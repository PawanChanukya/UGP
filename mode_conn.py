import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from scipy.special import comb

# Function to compute Bézier curve interpolation
def bezier_curve(t, theta1, theta2, bends):
    """
    Calculates the coordinates of the point given by parameter t on the curve 
    generated by thetas and bends.
    """
    k = len(bends) + 1
    control_points = [theta1] + [bends[i] for i in range(len(bends))] + [theta2]
    curve = [torch.zeros_like(theta1[i]) for i in range(len(theta1))]

    for j in range(k + 1): 
        coeff = comb(k, j) * (1 - t) ** (k - j) * t ** j  
        for i, param in enumerate(control_points[j]):
            curve[i] += coeff * param  

    return curve  

# Function to compute classification error (0-1 loss)
def compute_loss(model, weights, data_loader, device):
    """
    Compute 0-1 loss (classification error in percentage)
    """
    model.load_state_dict({k: w.clone().detach() for k, w in zip(model.state_dict().keys(), weights)})
    model.eval()

    total_samples = 0
    incorrect_samples = 0

    with torch.no_grad():
        for data, target in data_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            
            pred = (output > 0).float()
            incorrect_samples += (pred != target).sum().item()
            total_samples += target.size(0)

    loss = torch.tensor((incorrect_samples / total_samples) * 100 , device=device)
    return loss

# Function to train Bézier bends
def train_bezier_bends(model, theta1, theta2, k, train_loader, device, lr=0.01, steps=100):
    # Initialize bends correctly (structured as per model layers)
    bends = torch.nn.ModuleList([torch.nn.ParameterList([
        torch.nn.Parameter(p.clone().detach() + 0.01 * torch.randn_like(p)) 
        for p in theta1
    ]) for _ in range(k)])
    
    optimizer = optim.Adam(bends, lr=lr)

    for step in range(steps):
        optimizer.zero_grad()
        max_loss = torch.tensor(float('-inf'), device=device)

        for t in torch.linspace(0, 1, 50, device=device):
            weights = bezier_curve(t, theta1, theta2, bends)
            loss = compute_loss(model, weights, train_loader, device)  
            max_loss = torch.max(max_loss, loss.to(device))  # Ensure consistency

        max_loss.backward()
        optimizer.step()

        if step % 10 == 0:
            print(f"Step {step+1}/{steps}, Max Loss: {max_loss.item():.4f}")

    return bends

# def train_bezier_bends(model, theta1, theta2, k, train_loader, device, lr=0.01, steps=100):
#     # Define bends as k points, each with the same structure as theta1/theta2
#     class BendsWrapper(nn.Module):
#         def __init__(self, k, theta1):
#             super().__init__()
#             self.bends = nn.ModuleList([
#                 nn.ParameterList([
#                     nn.Parameter(p.clone().detach() + 0.01 * torch.randn_like(p)) for p in theta1
#                 ]) for _ in range(k)
#             ])

#         def forward(self):
#             return self.bends

#     bends_module = BendsWrapper(k, theta1).to(device)  # Create and move to correct device
#     optimizer = optim.Adam(bends_module.parameters(), lr=lr)  # Optimizer directly tracks parameters

#     for step in range(steps):
#         optimizer.zero_grad()
#         max_loss = torch.tensor(float('-inf'), device=device, requires_grad=True)

#         for t in torch.linspace(0, 1, 10, device=device):
#             weights = bezier_curve(t, theta1, theta2, bends_module())  # Use bends properly
#             loss = compute_loss(model, weights, train_loader, device)  
#             max_loss = torch.max(max_loss, loss)  # Ensure consistency

#         max_loss.backward()
#         optimizer.step()

#         if step % 10 == 0:
#             print(f"Step {step+1}/{steps}, Max Loss: {max_loss.item():.4f}")

#     return bends_module.bends  # Return bends in the correct structure


# Function to compute mode connectivity
def compute_mode_connectivity(model, theta1, theta2, bends, train_loader, device):
    """Compute mode connectivity using 0-1 loss, searching for the maximum loss barrier."""
    
    max_loss = float('-inf')
    for t in torch.linspace(0, 1, 10, device=device):
        weights = bezier_curve(t, theta1, theta2, bends)
        loss = compute_loss(model, weights, train_loader, device)
        max_loss = max(max_loss, loss)

    loss1 = compute_loss(model, theta1, train_loader, device)
    loss2 = compute_loss(model, theta2, train_loader, device)

    print(f"Loss1: {loss1:.4f}, Loss2: {loss2:.4f}, Max Loss: {max_loss:.4f}")

    return max_loss - (0.5 * (loss1 + loss2))
